{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "185a6c59",
   "metadata": {},
   "source": [
    "# Метод работы по спектрограмме\n",
    "Отрезок аудиозаписи должен быть продолжительностью не менее 10 секунд "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3ba65a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# system packages\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import shutil\n",
    "import librosa.display\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import pandas as pd\n",
    "import copy\n",
    "import math\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from pydub import AudioSegment\n",
    "import random\n",
    "# torch packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset,RandomSampler\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bccd21ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transforms = T.Compose([T.ToTensor()])\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "def infer(model,wav_file,window_size=1024, transforms= None):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    with torch.no_grad():\n",
    "        # раздел создания спектрограммы для классификации должен быть полностью \n",
    "        # идентичен разделу создания спектрограмм для тренировки. главное параметры n_fft=window_size, hop_length=512\n",
    "        #Audio = AudioSegment.from_wav(wav_file) # считываем аудио\n",
    "        #n=20\n",
    "        #sample = Audio[n*1000:(n+10)*1000]\n",
    "        #sample_name = './temp.wav'\n",
    "        #sample.export(sample_name, format=\"wav\")\n",
    "        \n",
    "        \n",
    "        y, sr = librosa.load(wav_file)\n",
    "        window = np.hanning(window_size)\n",
    "        stft  = librosa.core.spectrum.stft(y, n_fft=window_size, hop_length=512, window=window)\n",
    "        out = 2 * np.abs(stft) / np.sum(window)\n",
    "        fig = plt.Figure(frameon=False)\n",
    "        canvas = FigureCanvas(fig)\n",
    "        ax = fig.add_subplot(111)\n",
    "        ax.axis('off')\n",
    "        p = librosa.display.specshow(librosa.amplitude_to_db(out, ref=np.max), ax=ax)\n",
    "\n",
    "        # спктрограмма сохраняется во временный файл\n",
    "        temp = wav_file.split('/')[-1]\n",
    "        temp = r'./' + temp.split('.')[0]+'.png'\n",
    "\n",
    "        fig.savefig(temp\n",
    "                    ,pad_inches = 0)\n",
    "\n",
    "\n",
    "        # считываем так же как в классе Dataset\n",
    "        image = cv2.imread(temp, cv2.IMREAD_COLOR)\n",
    "        os.remove(temp)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        image /= 255.0\n",
    "\n",
    "\n",
    "        image_tensor = test_transforms(image).float()\n",
    "        image_tensor = image_tensor.unsqueeze_(0)\n",
    "        image_tensor.to(device)\n",
    "\n",
    "        # осуществляем предсказание\n",
    "        output = model(image_tensor)\n",
    "        # Я в качеству выходного слоя использую простой полносвязный слой потому переменная output  \n",
    "        # выглядит следующим образом tensor([[ 1.1148, -5.1110,  0.7156, -3.0015, -6.2952, -7.0076, -4.0860, -2.2178,\n",
    "        #     -3.6325, -2.1464,  4.4616,  0.0611]]). Я считаю что такой подход лучше всего \n",
    "        # потому что не связывает руки\n",
    "        index = torch.argmax(output, dim=1)\n",
    "        # В переменной index лежит индекс самого большого значения в тензоре. для примера выше это будет 10.\n",
    "        # Если нужно то тензор output можно переделать в тензор с вероятностями командами  \n",
    "        # sm = torch.nn.Softmax()\n",
    "        # probabilities = sm(b)\n",
    "        # тогда тензор с вероятностями для примера выше будет выглядеть следующим образом\n",
    "        # tensor([[3.2745e-02, 6.4759e-05, 2.1967e-02, 5.3391e-04, 1.9815e-05, 9.7192e-06,\n",
    "        #     1.8049e-04, 1.1690e-03, 2.8406e-04, 1.2556e-03, 9.3035e-01, 1.1417e-02]],\n",
    "        # и самая большая вероятность будет опять у элемента с индексом 10\n",
    "        return index, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fb3c6c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_model(num_classes):\n",
    "    '''\n",
    "    Эта функция возвращает экземпляр модели, построенной под наше количество классов.\n",
    "    Мы берем предобученную сеть, например mobilenet_v3_large и меняем ей \"голову\"\n",
    "    '''\n",
    "    model = models.mobilenet_v3_large(pretrained = True)\n",
    "    \n",
    "    #print(model)\n",
    "    \n",
    "    last_layer_input_features = model.classifier[-1].in_features\n",
    "    \n",
    "    model.classifier[-1] = nn.Linear(last_layer_input_features, num_classes, bias = True)\n",
    "    \n",
    "    #print(model)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "10b80a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = torch.nn.Softmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1e83838c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# путь к модели\n",
    "PATH = './best_spectrogram_12classes_10_noise.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "31a610c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNetV3(\n",
       "  (features): Sequential(\n",
       "    (0): ConvNormActivation(\n",
       "      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (2): Hardswish()\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvNormActivation(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
       "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): ConvNormActivation(\n",
       "          (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvNormActivation(\n",
       "          (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): ConvNormActivation(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
       "          (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ConvNormActivation(\n",
       "          (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvNormActivation(\n",
       "          (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): ConvNormActivation(\n",
       "          (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
       "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ConvNormActivation(\n",
       "          (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvNormActivation(\n",
       "          (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): ConvNormActivation(\n",
       "          (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
       "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): ConvNormActivation(\n",
       "          (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvNormActivation(\n",
       "          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): ConvNormActivation(\n",
       "          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): ConvNormActivation(\n",
       "          (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvNormActivation(\n",
       "          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): ConvNormActivation(\n",
       "          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): ConvNormActivation(\n",
       "          (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvNormActivation(\n",
       "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): ConvNormActivation(\n",
       "          (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): ConvNormActivation(\n",
       "          (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvNormActivation(\n",
       "          (0): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): ConvNormActivation(\n",
       "          (0): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n",
       "          (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): ConvNormActivation(\n",
       "          (0): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvNormActivation(\n",
       "          (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): ConvNormActivation(\n",
       "          (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
       "          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): ConvNormActivation(\n",
       "          (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvNormActivation(\n",
       "          (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): ConvNormActivation(\n",
       "          (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
       "          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): ConvNormActivation(\n",
       "          (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvNormActivation(\n",
       "          (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): ConvNormActivation(\n",
       "          (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "          (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(480, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): ConvNormActivation(\n",
       "          (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (12): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvNormActivation(\n",
       "          (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): ConvNormActivation(\n",
       "          (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): ConvNormActivation(\n",
       "          (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (13): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvNormActivation(\n",
       "          (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): ConvNormActivation(\n",
       "          (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
       "          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): ConvNormActivation(\n",
       "          (0): Conv2d(672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (14): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): ConvNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): ConvNormActivation(\n",
       "          (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (15): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): ConvNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): ConvNormActivation(\n",
       "          (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (16): ConvNormActivation(\n",
       "      (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (2): Hardswish()\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=960, out_features=1280, bias=True)\n",
       "    (1): Hardswish()\n",
       "    (2): Dropout(p=0.2, inplace=True)\n",
       "    (3): Linear(in_features=1280, out_features=12, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1=return_model(12) # создаем нашу модель\n",
    "model1.load_state_dict(torch.load(PATH))\n",
    "model1.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cccbe41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_to_class={0: 'Исправный, заводское состояние, новый',\n",
    "              1: 'Дефект наружнегл кольца, средний',\n",
    "              2: 'Дефект наружнего кольца, крупный',\n",
    "              3: 'Дефект внутреннего кольца, средний',\n",
    "              4: 'Дефект внутреннего кольца, крупный',\n",
    "              5: 'Дисбаланс 15 гр',\n",
    "              6: 'Дисбаланс 30 гр',\n",
    "              7: 'Промыт полностью от смазки. Отсутсивие смазки',\n",
    "              8: 'Недостаток смазки',\n",
    "              9: 'Грязь в смазке',\n",
    "              10: 'Сильно загрязнённая смазка',\n",
    "              11: 'Дефект наружнегл кольца, лёгкий'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3b499f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "пример выходного тензора tensor([[ -2.0225,  -6.2516,  -1.0000,  -7.9442,  -8.4857,   1.8636,   1.0736,\n",
      "          -2.0915,   2.2668,  -2.9575,  -6.8392, -14.5490]])\n",
      "вероятности классов tensor([[6.7172e-03, 9.7834e-05, 1.8674e-02, 1.8006e-05, 1.0478e-05, 3.2725e-01,\n",
      "         1.4852e-01, 6.2694e-03, 4.8976e-01, 2.6369e-03, 5.4363e-05, 2.4377e-08]])\n",
      "какой индекс получили из тензора tensor([8])\n",
      "сопоставление индекса и имени класса Недостаток смазки\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ysiberia\\AppData\\Local\\Temp\\ipykernel_17080\\3775193975.py:4: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  print(f'вероятности классов {sm(tensor)}')\n"
     ]
    }
   ],
   "source": [
    "# запуск модели иполучение ответов\n",
    "index,tensor=infer(model1,r'Зашумленные датасеты/10 процентов/split10/Test5-10/Test5-10_7_.wav')  \n",
    "print(f'пример выходного тензора {tensor}')\n",
    "print(f'вероятности классов {sm(tensor)}')\n",
    "print(f'какой индекс получили из тензора {index}')\n",
    "print(f'сопоставление индекса и имени класса {int_to_class[index.numpy()[0]]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f644da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9564a620",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "497e2e04",
   "metadata": {},
   "source": [
    "# Метод работы по векторному представлению"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a522d6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# system packages\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import librosa.display\n",
    "import time\n",
    "import scipy\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import math \n",
    "\n",
    "# ml packages\n",
    "from sklearn.preprocessing import StandardScaler    \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# torch packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# visualisation\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c0705d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_features(wav_path:str,num_mfcc:int):\n",
    "    '''\n",
    "    данная функция возвращает характеристики аудиофайла в виде вектора \n",
    "    и список названий характеристик\n",
    "    \n",
    "    ==Input==\n",
    "    wav_path - путь в аудиофайлу\n",
    "    num_mfcc - количество мел\n",
    "    '''\n",
    "    ff_list = [] # list values\n",
    "    ff_name_list=[] # list names\n",
    "    y, sr = librosa.load(wav_path, sr=None)\n",
    " \n",
    "    y_harmonic, y_percussive = librosa.effects.hpss(y) #Decompose an audio time series into harmonic and percussive components.\n",
    " \n",
    "    tempo, beat_frames = librosa.beat.beat_track(y=y_harmonic, sr=sr)\n",
    "    chroma = librosa.feature.chroma_cens(y=y_harmonic, sr=sr)\n",
    "    mfccs = librosa.feature.mfcc(y=y_harmonic, sr=sr, n_mfcc=num_mfcc)\n",
    "    cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    contrast = librosa.feature.spectral_contrast(y=y_harmonic, sr=sr)\n",
    "    rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "    zrate = librosa.feature.zero_crossing_rate(y_harmonic)\n",
    " \n",
    "    chroma_mean = np.mean(chroma, axis=1)\n",
    "    chroma_std = np.std(chroma, axis=1)\n",
    " \n",
    "    for i in range(0, len(chroma_mean)):\n",
    "        ff_list.append(chroma_mean[i])\n",
    "        ff_name_list.append(f'chroma_mean_{i}')\n",
    "    for i in range(0, len(chroma_std)):\n",
    "        ff_list.append(chroma_std[i])\n",
    "        ff_name_list.append(f'chroma_std_{i}')\n",
    "    mfccs_mean = np.mean(mfccs, axis=1)\n",
    "    mfccs_std = np.std(mfccs, axis=1)\n",
    " \n",
    "    for i in range(0, len(mfccs_mean)):\n",
    "        ff_list.append(mfccs_mean[i])\n",
    "        ff_name_list.append(f'mfccs_mean_{i}')\n",
    "    for i in range(0, len(mfccs_std)):\n",
    "        ff_list.append(mfccs_std[i])\n",
    "        ff_name_list.append(f'mfccs_std_{i}')         \n",
    "    cent_mean = np.mean(cent)\n",
    "    cent_std = np.std(cent)\n",
    "    cent_skew = scipy.stats.skew(cent, axis=1)[0]\n",
    "\n",
    " \n",
    "    contrast_mean = np.mean(contrast,axis=1)\n",
    "    contrast_std = np.std(contrast,axis=1)\n",
    " \n",
    "    rolloff_mean=np.mean(rolloff)\n",
    "    rolloff_std=np.std(rolloff)\n",
    "\n",
    "    data = np.concatenate(([cent_mean, cent_std, cent_skew], \n",
    "                           contrast_mean, contrast_std, \n",
    "                           [rolloff_mean, rolloff_std, rolloff_std]), axis=0)\n",
    "    ff_list += list(data)\n",
    "    ff_name_list+=['cent_mean', 'cent_std', 'cent_skew']\n",
    "    for i in range(0,len(contrast_mean)):\n",
    "        ff_name_list.append(f'contrast_mean_{i}')\n",
    "    for i in range(0,len(contrast_std)):\n",
    "        ff_name_list.append(f'contrast_std_{i}')\n",
    "    ff_name_list+=['rolloff_mean', 'rolloff_std', 'rolloff_std']\n",
    "    \n",
    "    \n",
    "    zrate_mean = np.mean(zrate)\n",
    "    zrate_std = np.std(zrate)\n",
    "    zrate_skew = scipy.stats.skew(zrate,axis=1)[0]\n",
    " \n",
    "    ff_list += [zrate_mean, zrate_std, zrate_skew]\n",
    "    ff_name_list+=['zrate_mean', 'zrate_std', 'zrate_skew']\n",
    "    ff_list.append(tempo)\n",
    "    ff_name_list.append('tempo')\n",
    " \n",
    "    return ff_list,ff_name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5d6e1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c201f279",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MulticlassClassification(nn.Module):\n",
    "    def __init__(self, num_feature, num_class):\n",
    "        super(MulticlassClassification, self).__init__()\n",
    "        \n",
    "        self.layer_1 = nn.Linear(num_feature, 1024)\n",
    "        self.layer_2 = nn.Linear(1024, 512)\n",
    "        self.layer_3 = nn.Linear(512, 256)\n",
    "        self.layer_4 = nn.Linear(256, 128)\n",
    "        self.layer_5 = nn.Linear(128, 64)\n",
    "        self.layer_out = nn.Linear(64, num_class) \n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(1024)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(512)\n",
    "        self.batchnorm3 = nn.BatchNorm1d(256)\n",
    "        self.batchnorm4 = nn.BatchNorm1d(128)\n",
    "        self.batchnorm5 = nn.BatchNorm1d(64)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer_1(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.layer_2(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.layer_3(x)\n",
    "        x = self.batchnorm3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.layer_4(x)\n",
    "        x = self.batchnorm4(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.layer_5(x)\n",
    "        x = self.batchnorm5(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.layer_out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5acb5904",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FEATURES=72\n",
    "NUM_CLASSES = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4959d1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = torch.nn.Softmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c869670",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_weights = './best_vector_12_classes_10_noise_new.pt' # куда сохраняем веса с лучшим результатом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb705edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MulticlassClassification(\n",
       "  (layer_1): Linear(in_features=72, out_features=1024, bias=True)\n",
       "  (layer_2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (layer_3): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (layer_4): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (layer_5): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (layer_out): Linear(in_features=64, out_features=11, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (batchnorm1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batchnorm2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batchnorm3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batchnorm4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batchnorm5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# сначала надо создать объект нейронной сети, он будет как бы пустой\n",
    "model = MulticlassClassification(num_feature = NUM_FEATURES, num_class=NUM_CLASSES)\n",
    "# загрузить в него веса этой же но обученной сети\n",
    "# если архитектура \"пустышки\" будет отличаться от архитектуры которую загружаем то будет ошибка\n",
    "model.load_state_dict(torch.load(best_weights)) # веса взяты из обучения\n",
    "model.eval() # включаем режим предсказания (отключаем обратное распространение ошибки)\n",
    "model.to(device) # отправляем на устройство"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9ace0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_to_class={0: 'Исправный, заводское состояние, новый',\n",
    "              1: 'Дефект наружнегл кольца, средний',\n",
    "              2: 'Дефект наружнего кольца, крупный',\n",
    "              3: 'Дефект внутреннего кольца, средний',\n",
    "              4: 'Дефект внутреннего кольца, крупный',\n",
    "              5: 'Дисбаланс 15 гр',\n",
    "              6: 'Промыт полностью от смазки. Отсутсивие смазки',\n",
    "              7: 'Недостаток смазки',\n",
    "              8: 'Грязь в смазке',\n",
    "              9: 'Сильно загрязнённая смазка',\n",
    "              10: 'Дефект наружнегл кольца, лёгкий'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6757e351",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(model,file_path,num_mfcc,windows_size = 1024):\n",
    "    '''\n",
    "    Векторизуем аудиофайл и отправляем в сеть. Тут все параметры векторизации должны совпадать \n",
    "    с параметрами векторизации которые были при создании датасета для обучения. \n",
    "    чтобы размерность векторов совпадала\n",
    "    ===Input===\n",
    "    model - модель которая будет осуществлять предсказание\n",
    "    file_path - путь в аудиофайлу\n",
    "    num_mfcc - количество мел-кепстров которые будет доставать из аудио\n",
    "    \n",
    "    '''\n",
    "    with torch.no_grad():\n",
    "        vector, names = get_base_features(file_path,num_mfcc)\n",
    "        vector = torch.FloatTensor(vector)\n",
    "        vector = vector.unsqueeze_(0)\n",
    "        vector.to(device)\n",
    "\n",
    "         # осуществляем предсказание\n",
    "        output = model(vector)\n",
    "        # Я в качеству выходного слоя использую простой полносвязный слой потому переменная output  \n",
    "        # выглядит следующим образом (tensor([[ 7.3186, -2.7376, -3.3811, -2.7901, -4.9589, -2.8915, -2.0703, -4.0185,\n",
    "        #  -3.1207, -3.0112, -1.7625, -4.7538]]). Я считаю что такой подход лучше всего \n",
    "        # потому что не связывает руки\n",
    "        index = torch.argmax(output, dim=1)\n",
    "        # В переменной index лежит индекс самого большого значения в тензоре. для примера выше это будет 10.\n",
    "        # Если нужно то тензор output можно переделать в тензор с вероятностями командами  \n",
    "        # sm = torch.nn.Softmax()\n",
    "        # probabilities = sm(b)\n",
    "        # тогда тензор с вероятностями для примера выше будет выглядеть следующим образом\n",
    "        # tensor([[9.9958e-01, 4.2901e-05, 2.2542e-05, 4.0708e-05, 4.6534e-06, 3.6782e-05,\n",
    "        # 8.3619e-05, 1.1917e-05, 2.9250e-05, 3.2634e-05, 1.1375e-04, 5.7129e-06]]),\n",
    "        # и самая большая вероятность будет опять у элемента с индексом 0\n",
    "        return output,index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "39cf31a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "пример выходного тензора tensor([[ 20.1238,   2.5616, -33.6511,  -8.0080, -14.4073, -13.1352,   8.8881,\n",
      "         -22.0474, -22.6461, -21.0331, -18.7734]])\n",
      "вероятности классов tensor([[9.9999e-01, 2.3594e-08, 4.4241e-24, 6.0604e-13, 1.0077e-15, 3.5957e-15,\n",
      "         1.3194e-05, 4.8447e-19, 2.6623e-19, 1.3359e-18, 1.2798e-17]])\n",
      "какой индекс получили из тензора tensor([0])\n",
      "сопоставление индекса и имени класса Исправный, заводское состояние, новый\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ysiberia\\AppData\\Local\\Temp\\ipykernel_19308\\3897188829.py:3: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  print(f'вероятности классов {sm(tensor)}')\n"
     ]
    }
   ],
   "source": [
    "tensor,index = infer(model,r'C:\\Users\\Ysiberia\\Documents\\GitHub\\audiio_classification\\Зашумленные датасеты\\10 процентов\\split10\\Test8-10\\Test8-10_5_.wav',12)\n",
    "print(f'пример выходного тензора {tensor}')\n",
    "print(f'вероятности классов {sm(tensor)}')\n",
    "print(f'какой индекс получили из тензора {index}')\n",
    "print(f'сопоставление индекса и имени класса {int_to_class[index.numpy()[0]]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0100f55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
